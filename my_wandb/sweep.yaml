program: bert_train.py
method: bayes
metric:
  name: "loss"
  goal: minimize
parameters:
  tau:
    distribution: categorical
    values:
      - 1
  epochs:
    distribution: int_uniform
    min: 5
    max: 20
  ff_dim:
    distribution: categorical
    values: [ 32, 64, 128, 256, 512 ]
  dropout:
    distribution: categorical
    values: [ 0.1, 0.125, 0.15, 0.2, 0.25, 0.3 ]
  n_layers:
    distribution: int_uniform
    min: 1
    max: 4
  window_size:
    distribution: categorical
    values: [ 64, 128, 256, 480, 512 ]
  batch_size:
    distribution: categorical
    values: [ 128, 256, 512, 1024 ]
  head_size:
    distribution: categorical
    values: [ 32, 64, 128, 256 ]
  num_heads:
    distribution: int_uniform
    min: 1
    max: 8
  optimizer:
    distribution: categorical
    values:
      - adam
  lambda_val:
    distribution: categorical
    values: [ 0.05, 0.1, 0.15, 0.2]
  output_size:
    distribution: categorical
    values:
      - 1
  on_threshold:
    distribution: categorical
    values:
      - 2000
  learning_rate:
    distribution: uniform
    min: 0.000005
    max: 0.0002
  conv_activation:
    distribution: categorical
    values:
      - relu
      - gelu
  masking_portion:
    distribution: categorical
    values: [ 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.35]
  bias_initializer:
    distribution: categorical
    values:
      - zeros
  conv_kernel_size:
    distribution: categorical
    values: [ 3, 5]
  dense_activation:
    distribution: categorical
    values:
      - relu
      - gelu
  deconv_kernel_size:
    distribution: categorical
    values: [ 3, 5]
  kernel_initializer:
    distribution: categorical
    values:
      - glorot_uniform
  layer_norm_epsilon:
    distribution: categorical
    values: [ 3e-4, 7e-4, 1e-3, 3e-3, 7e-3, 1e-2]